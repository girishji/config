
Press F1 when typing a function name, for help

==

list can have names. To get value:
either do: listx[[name]] or listx$name

Note: listx[name] gives you a list with 1 element

==
memory address:

assign ("abc",5)
get("abc")
Confirming that the memory address is identical:

getabc <- get("abc")
pryr::address(abc) == pryr::address(getabc)
# [1] TRUE

==
This will print all rows of a dataframe:
options(datatable.print.nrows=Inf)
==

how to use local()

result <- local({
  x <- rnorm(foo)
  y <- rnorm(bar)
  (x + y) * w
})

If a function is used only once, you can replace
the function with above local()

all variables inside loca() are not exposed to global scope, just like a function() {}. Similarly, all global variables are available inside both local({}) and function(){}

==

print() vs cat()
The nature of R means that you're never going to have a newline in a character vector when you simply print it out.

> print("hello\nworld\n")
[1] "hello\nworld\n"

That is, the newlines are in the string, they just don't get printed as new lines. However, you can use other functions if you want to print them, such as cat:

> cat("hello\nworld\n")
hello
world

==
data.table:
dt[, colname] => returns a vector (same as dt$colname)
dt[, .(colname)] => returns a data.table

# number of columns
length(dt)
ncol(dt)
# number of rows
nrow(dt)
length(dt$somecolname)
dt[, .N]
dt[, nrow(.SD)]

if a column (colname) is 0's and 1's or logical (TRUE/FALSE),
then, dt[colname, .(something)] does not work,
do dt[(colname), .(something)], or better 
do dt[colname == 1, .(something)]

dt[, { put any function in here} ]
wa[, {hist(price)}]
wa[, {plot(density(price))}]

for data.table see cheatsheet embedded in https://rdatatable.gitlab.io/data.table/

for melt and dcast do: vignette("datatable-reshape") from r console.
or http://127.0.0.1:19672/library/data.table/doc/datatable-reshape.html

first(datatable) to print first row (better than head)

plotting in 3.7.4.3 in https://franknarf1.github.io/r-tutorial/_book/tables.html#exploring-data is best
==

23L is integer
23 is numeric
class() will tell you that
for complex objects and lists use str()

How to filter in vector/list: (search for "filter" below)
create a vector of TRUE and FALSE and use it to index the given vector.

==

to create a vector (or any object like array) and set its names:
test <- setNames(c(1, 2), c("A", "B"))

do ?setNames

==

make use of 'iris' and 'mtcars' built in dataframes for experimentation
==
to collapse a vector of strings (character) to a single string
paste(vector1, collapse = " ") or
paste(vector1, collapse = "-")
as in:
paste(range(wa$price), collapse = " ")

==

String functins:

http://www.endmemo.com/r/stringfunc.php

>s <- "EndMemo.com R Language Tutorial"
>substr(s,0,7)
[1] "EndMemo"

Get string length:

>nchar(s)
[1] 31

To uppercase:
>x <- toupper(s)
>x
[1] "ENDMEMO.COM R LANGUAGE TUTORIAL"

To lowercase:
>x <- tolower(s)
>x
[1] "endmemo.com r language tutorial"

Split the string at letter "o":
>x <- strsplit(s,"o")
[[1]]
[1] "EndMem" ".c" "m R Language Tut" "rial"

Concatenate two strings:
>x <- paste(x," -- String Functions",sep="")
>x
[1] "endmemo.com r language tutorial -- String Functions"

Substring replacement:
>x <- sub("Tutorial","Examples",s)
>x
[1] "EndMemo.com R Language Examples"

Use regular expression:
>x <- sub("n.+e","XXX",s)
>x
[1] "EXXX Tutorial"

grep() is in http://www.endmemo.com/r/grep.php

grep(pattern, x, ignore.case = FALSE, perl = FALSE, value = FALSE,
fixed = FALSE, useBytes = FALSE, invert = FALSE)

grep() function searchs for matches of a string or string vector. It returns a vector of the matched elements or their indices.
see this link for examples of grep():
http://www.endmemo.com/r/grep.php

Quirk with grep(): It returns a integer(0), meaning a 0 length
vector when match fails. To test it in a if statement you 
should use length():
if (length(grep('new_sp_m', 'new_sp_m04')) {} 

or use grepl(), meaning, grep-logical
• grepl returns a logical vector (match or not for each element of x).

> x <- grepl("ex",str)
> x
[1] FALSE TRUE TRUE

sub and gsub return a character vector of the same length and with the same attributes as x (after possible coercion to character). 

The difference is that sub only replaces the first occurrence of the pattern specified, whereas gsub does it for all occurrences (that is, it replaces globally). 

==

To count number of occurances of different value inside a column of
a datatable or dataframe:
table(TB$age)
table(Prestige$type, Prestige$inc) # to get 2-D table, both type 
		# and inc are character (strings) here
or
use unique(vector/list) to get unique values

==

Best intro: https://franknarf1.github.io/r-tutorial/_book/basics.html#basics
- to get help for say -> operator: type ?`->` 
  you only need backticks for special characters like ->
  To see examples run example('foo')
- scalars are actually vectors in R with length=1
- str() vs class()
- vector vs class vs scalar (and coercion)
- why it says [1] when it prints vector, while it says
   [[n]] when it prints list (section 2.1.2)
- vectors can be named too; if not named it prints [1] 
> x <- c('a', 'b')
> x
[1] "a" "b"
> x[2]
[1] "b"
> y <- c(f='a', g='b')
> y
  f   g 
"a" "b" 
> y[1]
  f 
"a" 
> y[c('f','g')]
  f   g 
"a" "b" 

- use () liberally in expressions, don't think too much about guessing precedence of operators

- Sometimes, we need closer inspection for debugging. The functions unclass (which removes the class) and dput (which prints R code to create the object) are helpful for this. See 3.6.4.5 for an example relevant to date and time objects.

- 2.1.2 Classes (in vectors and lists)

Every vanilla vector has a single class. That is, every element of the vector contains the same type of data:

c(4, c("A", "B"))
# [1] "4" "A" "B"
Coercion: The 4 is “coerced” to character above, with no warning. Since coercion is so central to R and confusing for new users, I strongly suggest reading its documentation, in the Details section of ?c.

The doc at ?c also conveniently lists all of the vanilla (“atomic”) classes. The key ones are:

Logical: Use TRUE or FALSE.
Integer: Write L at the end: 1L, 2L, etc. The L will not be displayed in output.
Numeric: Write it as usual or with e notation, 2, 3.4, 3e5.
Character: Use single or double quotes, "bah", 'I say "gah"', etc.

A list is a special type of vector whose elements can be arbitrary objects, for example, a list of vectors:

# example data
L  = list("A", c(1,2))
L2 = list(FALSE)
L3 = c(L, L2)
L3
# [[1]]
# [1] "A"
# 
# [[2]]
# [1] 1 2
# 
# [[3]]
# [1] FALSE

The [[1]] printed here indicates the first element of the list, similar to the [1] we see for atomic vectors.

Fancier classes are generally built on top of atomic classes or lists. Behind the scenes, date formats are numeric or integer; while complex objects like data sets and regression results are lists. For details on storage modes, see ?typeof and the R internals documentation. While some fancy data structures like linked lists and unordered sets are absent in base R, they can be used through packages like Rcpp.

For lists, in addition to a length, we also have lengths, measuring each element:

lengths(L3)
# [1] 1 2 1

The class of an object can be tested with is.logical, etc.

- To compare two objects, use == and !=. R will silently coerce the objects’ classes to match:

"4.11" == 4.11
# [1] TRUE

- x[-c(2, 3)] # everything excluding 2nd and 3rd element

- 2.1.6 missing values: 

R differs from other programming languages in its careful treatment of missing values in the reading and processing of data. The missing-data code NA is distinct from other special codes:

* a non-number, NaN;
* positive and negative infinity, Inf and -Inf; and
* the absence of an object, NULL.

A missing value means “there is a value here, but we don’t know what it is.” So a comparison against a missing value, like 2 == NA or 2 != NA, will always return NA, since we cannot determine whether the condition is true or false. To test whether a value is missing, use the is.na function.

Advanced stuff: Implementation of missing values. The class of an NA is different depending on the vector it is in. Sometimes, it is important to ensure that a missing value belongs to a particular class. To ensure this, the safest approach is to “slice” an object of that class with NA_integer_. For example, to get a missing numeric value, we can use the number 10 like 10[NA_integer_]; or for a date value, we can use the current date, Sys.Date(), like Sys.Date()[NA_integer_].

- 2.1.8: slicing vs extracting ; [] vs [[]] 
- The slice L["Z"] is a list containing just one element; while L[["Z"]] actually is the element.
L$Z offers a handy alternative way of extracting by name from a list, but it is tougher to write a program around.
- string operations are in section 4.8
- print and cat can both be used to print output to the screen, with various options. Of the two, cat will actually parse the string, so cat('Egad!\nI dare say, "It\'s you!"\n') will print the newlines and quotes.
- 2.1.10/11 assigning and initilizing
- integer sequence is x:y
- seq_along is goog for iteration: If we are running 1...length(x) alongside some vector x, then seq_along is the right tool
- also: If we are running 1..n where n is a nonnegative integer variable, it is safer and more efficient to use seq_len than 1:n
- It is not worth trying to make sense of R’s naming conventions.
- seq(), seq.date, seq.int etc
- 2.1.13 is sorting vs ordering
	There are three key functions here:

	sort(x) will sort the vector.
	rank(x) tells where each element of x is in the pecking order.
	order(x) is rarely useful on its own, but y[order(x, z)] will sort y by x and z.

to reverse order: x[order(-y)]

- R doesn’t do error codes, only error messages and warnings.
- 2.3 The parser interprets ; as the end of a command, so three commands x <- 10; y <- 5; x + y can be written on a single line. This is rarely useful when writing a program.

The {...} braces will return their last value, so {x <- 10; y <- 5; x + y} will return 15. It will also have the side effect of creating x and y. To avoid this side effect, use local, like

local({
  x <- 10
  y <- 5
  x + y
})

- 2.3.1 esoteric stuff
- 2.3.2 arithmatic: The full set of arithmetic operators is documented at ?Arithmetic. The integer division and modulo operators look like %/% and %%, but otherwise, everything is standard.

- logical operators (& vs && etc): The self-explanatory symbols !, & and | are used to construct compound logical tests.
A couple additional symbols, || and &&, do short circuiting and will be explained in 2.3.4.

For a logical vector, any() and all() summarise it in the natural way.

Aside:
%/% and %% for integer division and modulo;
%in% to test membership (see 4.1);
%*% for matrix multiplication; and

- 2.3.4 vectorizing: 
Most operations in R are performed elementwise:

x = c(1, 2)
y = c(2, 3)
x / y
# [1] 0.5000000 0.6666667
x ^ y
# [1] 1 8

We call functions with this behavior “vectorized.” 
R is a lot faster when operations are performed elementwise rather than in a loop, so there’s a common mantra to “vectorize your code,” especially when doing arithmetic. The idea is similar to translating a statistical model into matrix algebra.

A couple of notably non-vectorized functions are && and ||. These will (silently) only look at the first element on each side; and if the result can be determined using the left-hand side, for example in FALSE && yodel-e-hee-hoo, then the right-hand side will not be evaluated. These are useful mostly for improving efficiency on the margins.

Aside: Recycling, again. As we saw in 2.1.7, recycling kicks in for any vectorized function. So we have c(-2,2) ^ c(1,2,3,4) working, with no warning given. Fortunately, there is a warning if the recycling is imperfect, like c(-2,2) ^ c(1,2,3).

- Recycling 
x = c("a", "b", "c", "d")
x[c(FALSE, TRUE, TRUE, FALSE)]
# [1] "b" "c"

Recycling: What would be the natural behavior of x[TRUE] in the example above? Well, in R, it acts like x[c(TRUE, TRUE, TRUE, TRUE)], without giving any warning. This is called recycling – the argument i is repeated until it is long enough for the context it is used in. What about x[c(TRUE, FALSE)]? The full rules for recycling can be found in the R intro doc.

- I skipped the part about Matrix and Array

- Some excercises:
2.3.7 Exercises
1) From x = 1:4, use the functions introduced so far to compute how many elements are greater than 1.
ans: 
x=1:4
> x
[1] 1 2 3 4
> sum(x > c(1))
[1] 3
(notice that Recycling happened. c(1) was promoted to c(1,1,1,1)
and then after > you get c(false, true, true, true)

2) Read ?log10 and use it to round x = 40 up to the next order of magnitude, like 10^(_fill_this_in_).
and:
> round(log10(40))
[1] 2

3) From x = c(NA, 1, 33), filter to elements greater than 10 (and not missing), like x[_fill_this_in_]
ans:
x[!is.na(x)][x[!is.na(x)] > 10]

4) Read ?rev and from x = 1:10, extract the last three elements using head and rev. What is a more direct way?
ans:
> head(rev(x),3) vs tail(x, 3)

5) Why does NA | 1 evaluate to TRUE?
funda:
* NA | TRUE is true, since no matter what the missing value is (TRUE or FALSE), the compound statement must be true.
* NA & TRUE is NA, since we need to know the missing value to determine the truth or falsehood of the compound statement.
Note:
Logic with numeric values. Numbers are treated as FALSE when zero and TRUE otherwise. This allows us to use length(x) as a test instead of length(x) > 0.

6) Read ?abs and figure out why abs(NA) + 1 > 0 evaluates to NA. Should it?
No. NA means we don't know the value. It could be 0, and abs(0)=0.

- 2.4 Functions (read about global namespace pollution in 2.5.1, even 
i's of for loop pollute global space):

If you simply did install.packages("fortunes"), then you have
to use "::" when you use a function in that package.
fortunes::fortune(111), will work
If you don't want to use "::" then attach it with library().
library(fortunes)
fortune(111), will work
The downside to attaching a package is the risk of “namespace conflicts”, since everything enters the global namespace
and functions with same names will conflict with local
functions and functions from other packages.

Misc stuff:
To read the doc for a function in a package, just write the full path, like ?fortunes::fortune. To see a listing of functions provided by a package, use help(package="fortunes")
Type sessionInfo() to see which packages are loaded
Use installed.packages to view dependencies and version numbers

Passing arguments out-of-order and by name:
x = vector(length = 5, mode = "list")
The arguments are being passed out-of-order, but it still works since the arguments are being passed by name. Passing arguments by the position, like sort(x, TRUE), is a riskier proposition, since it is harder to get right initially and to interpret correctly later.

- 2.4.3 Iterating over a list (use lapply to get a list, 
  or sapply to get a vector as a result)

To apply the same function to every element of a list, use lapply.

> lapply(list(c(3,1,4), c(2,7,9), 0), min)
# [[1]]
# [1] 1
# 
# [[2]]
# [1] 2
# 
# [[3]]
# [1] 0

lapply() is a very important tool in R and will come up again and again.

When the function’s return value is guaranteed to be a scalar, sapply or vapply may be a better choice, but I almost never need those in practice.

- 2.4.4 Writing functions
Like any other object, functions can be assigned with <- or =:

f = function(x) x^2 + 3
f(4)
Or steal a function from elsewhere:

f = fortunes::fortune
For more complicated functions, use {}:

f = function(x){
  x[1] = 999
  return(x)
}

If no return command is given, the last value is used. To return multiple objects, combine them in a list and return it instead.

- 2.4.5 Scoping (FUNCTIONS ARE PASS BY VALUE, pass by reference 
is disouraged)

Consider a function that modifies its input:

# example function
f = function(x){
  x[1] = 999
  return(x)
}

Does modification inside the function alter the object passed to it?

> z = c(1,2,3)
> f(z)
# [1] 999   2   3
> z
# [1] 1 2 3

There are ways to write functions with pass-by-reference in base R (<<- and assign), but these are discouraged

Note: data.table package uses pass-by-reference extensively though.

- 2.4.6 Lazy evaluation (global scope variables are visible inside
the functions, and they are accessed only when needed (lazy))

Now let’s see how global variables called inside a function are handled.

y = 1
g = function(x) x + y
y = 2
g(1)
# [1] 3
y = 3
g(1)
# [1] 4
So R only looks for y when it needs it and no sooner. This is called “lazy evaluation.”

- 2.4.7 Environment (there is a way to bind globals to a function
using "with" statement. Read it if needed.

- 2.4.8 Default arguments (as you would expect)

- 2.4.9 Finding a function by name
When I run into a function and don’t know what package it is from, besides searching online, I also sometimes use help.search or its ?? shortcut, like ??fortunes. This will search all installed packages.

- 2.4.10 Inspecting function source code
To inspect the R code behind a function, as with any other R object, just type its name:

> nrow
(prints out source code for nrow())

Advanced stuff: Many functions are not “exported” for direct use. Nonetheless, their code may be found using getAnywhere or accessed directly using ::: syntax:

getAnywhere(head.default)
utils:::head.default
Many such hidden functions are “methods”; see ?Methods. There are also several functions that should be hidden, documented at ?.subset, ?.getNamespace and elsewhere.

C code:
Often, the source code for base R functions is in C and is fairly readable even for the C-illiterate. Following Joshua Ulrich’s instructions:

Navigate to a copy of the source code.
Browse to /src/main/names.c
Read the c-entry column for the function of interest.
Search the text of /src/main/*.c for it.

- 2.5 Loops and control flow 
As in most programming languages, we have for loops, if/else blocks, and so on. Some quirks to note:

* Write for (i in idx) ... to iterate over the vector idx, even its duplicates.
* Write else if, since there is no elseif, elsif or elif.
* Use next to bust out of the current iteration of a loop.
* Use break to bust out of the loop entirely.

Don't forget lapply and sapply and seq_along

- 2.5.1 Thinking about for loops (pollution of global variables and sapply)

Suppose we have this loop to compute x[i] from idx[i]:

idx = c(1, 2, 3, 4, 5)

x = numeric(length(idx)) # creates a vector of 0's see ?numeric
for (i in idx){
  i2    = i^2
  x[i]  = 2*i2 - 1
}

There are a couple problems here:

* The global environment is polluted by i and i2 in the end.
* There is no need for an iterative approach, since each x[i] can be computed independently.

A sibling to lapply, our tool for iterating over lists from 2.4.3, can help:

idx = c(1, 2, 3, 4, 5)
x = sapply(idx, function(i){
  i2    = i^2
  return(2*i2 - 1)
})

Of course, there is still one further problem:

This task can be done with vectorized code!
idx = c(1, 2, 3, 4, 5)
i2  = idx^2
x   = 2*i2 - 1

Vectorized code and matrix algebra are much faster than a loop. Loops should be reserved for tasks that really must be performed iteratively. When speed becomes an issue for such tasks, it is time to learn the Rcpp family of packages, which allow for coding in C++.

Aside: Breaking an operation: When running a malfeasant loop (eating up too much memory or taking too long) in the R console, the operation can be broken by pressing ESC. This applies elsewhere in R as well, but I usually run into it with loops or one of the several functions documented at ?lapply.

- 2.5.2 if/else elementwise
The base R tool for handling elementwise if/else rules is the function ifelse. 

Aside: First, if tempted to do x = if (cond) 1 else 0, don’t. As mentioned in 2.3.2, the logical variable cond itself is perfect for storing this dummy variable.

Excercise: Write a vectorized function for the root mean squared deviation between two vectors, sqrt(1/n sigma(x_i - y_i)^2.
 where n is how long the vectors are. For x = 1:4; y = c(6,1,4,1) it should return 3.
Ans:
Don't try lapply or sapply. You should think of doing vector/matrix
algebra directly. This is how R is different.
> sqrt(sum((x-y)**2) / length(y))
[1] 3

- R includes several handy constants, like pi, the alphabet (?letters), months (?month.name), days of the week (?weekdays) and US state names and abbreviations (?state). 

- He has a whole section on data.table and some data.frame


- Basic data.frame:

DF = data.frame(
  x = letters[c(1, 2, 3, 4, 5)], 
  y = c(1, 2, 3, 4, 5), 
  z = c(1, 2, 3, 4, 5) > 3
)

#   x y     z
# 1 a 1 FALSE
# 2 b 2 FALSE
# 3 c 3 FALSE
# 4 d 4  TRUE
# 5 e 5  TRUE

View(DF)

Data frames are printed with observations on rows and variables on columns. In many ways, they behave like matrices: working with functions like dim, ncol, nrow, head and tail; using DF[i, j] syntax for slices; and even using DF[im] syntax for matrix indexing.

DF[3, ]

DF[, "z", drop=FALSE] 
drop=F means keep the name of column ('z' here) and you
get a data.frame; otherwise it returns a pure vector (by default drop=T)
> class(DF[, "z", drop=F])
[1] "data.frame"

Note: If the data already is entirely numeric and the remaining analytical tasks are all linear algebra, a matrix will be simpler and almost always computationally faster than a data frame.

- 2.6.1  Iterating over columns

It is useful to keep in mind that data frames are really lists of columns, not matrices. We can use lapply (2.4.3) to iterate over such lists:

lapply(DF, function(x) x[3]) # get 3rd row

Imp: We can use coercion above. We can also get the result of that lapply call by coercion to a list: as.list(DF[3, ]). The names of similar functions can be guessed: as.matrix, as.data.frame, as.vector, as.logical, as.integer, as.numeric, as.character, as.factor, and so on. There is as(x, "class_name"), but I have found the latter to be finicky.


- data.table
  * 'j' can be any complicated funciton, see 3.2.4.4 
  * SQL 'join' is 'merge()' of data.table; then you have melt() and dcast()
	ex: a[b, on=.(id)] XXX: cannot specify as on=id, it
	has to be on=.(id), for by= and on= you should better
	use on=c("foo", "bar") => most foolproof

  * DT[where, select|update|do, by] # SQL verbs (no "do" in
	standard SQL, only in postgre sql - just executes
	a bunch of code like a function with void return value; 	'update' modifies the database with new values	
  * See 3.9 for notation cheatsheet
  * https://franknarf1.github.io/r-tutorial/_book/tables.html#tables
  * With :=, the table is not printed after the changes are made. To overcome this, it’s idiomatic to add a trailing [], like exDT[, (newcols) := newvals][].


=======================================
==

Some data.frame stuff:

votes[5, c("PROVINCE", "NAME")]
votes[1, "PROVINCE"]
votes$PROVINCE

# Adding a new column to a data.frame:

votes$PARTICIPATION <- votes$VOTES/votes$REG_VOTERS
votes$ONES <- 1
votes$TWOS <- 2

# checking the column names:
colnames(votes)
# rownames(votes) in case you need it

also ncol(df), nrow(df) and dim(df)

# changing the name of a column:

colnames(votes)[19] <- "twos"
colnames(votes)

# Removing a column from a data.frame
votes$ones <- NULL
or
votes <- votes[,-18]
or
votes <- votes[,!colnames(votes) %in% c("THREES")]

# Choosing subsets by logical expressions:

votes[votes$PROVINCE == "Mazowieckie",]
votes[votes$PROVINCE == "Mazowieckie",][1:5,]
votes[votes$PROVINCE == "Mazowieckie",1:4]
votes[votes$V_PIS > 2000 & votes$V_KO > 2000,]
votes[votes$V_PIS > 2000 & votes$V_KO > 2000,]$NAME
votes$NAME[votes$V_PIS > 2000 & votes$V_KO > 2000]
votes$NAME[votes$V_PIS > 2000 | votes$V_KO > 2000]
votes$NAME[is.na(votes$V_JEDN)]

# Data frame sorting:

votes <- votes[order(votes$REG_VOTERS),]
votes <- votes[order(-votes$REG_VOTERS),]
votes <- votes[order(votes$REG_VOTERS, votes$VOTES),]

# removing NAs

votes1 <- na.omit(votes)
votes2 <- votes[!is.na(votes$V_GWIA),]

# adding more rows and columns

rbind(df_1, df_2) => take the df_2 and paste it below df_1 and return the new df. r stands for row
similarly cbind(), which binds columns side by side.
votes3 <- rbind(votes1, votes2)

# misc:

Vector operator %in%: this operator will return true if element of vector_1 belongs to vector_2 (meaning if this element is one of the elements of vector_2). Use it as "vector_1 %in% vector_2". You get a vector of TRUE and FALSE

vector operator ifelse(condition, value if true, value if false)

"&" is a vector operator. "and" is a scalar operator

order() will sort columns in a data frame

Data frame (called data.frame): columns should all have same type of elements
Think of data frame as a list (dictionary like) where name (key) is the name of the column, and each column is a vector of similar type values. when printed, data frame is displayed with vectors in vertical columns.

data_frame[row_x,column_y] is how you refer to element. data frame is always 2-dimensional. can also use data_frame$column_name

==

.SD, when you group by something, is a data.table (for each group) within the
large data.table. This means you can refer to rows within the group.
To subtract first row (one of the columns) from second row within a group, do:
data.table(Data)[, .SD[2L, Unemployment] - .SD[1L, Unemployment], by = "Country"]

Recall that .SD is itself a data.table, and that .N refers to the total number of rows in a group (it’s equal to nrow(.SD) within each group), so .SD[.N] returns the entirety of .SD for the final row associated with each teamID.

Another common version of this is to use .SD[1L] instead to get the first observation for each group, or .SD[sample(.N, 1L)] to return a random row for each group.

https://cran.r-project.org/web/packages/data.table/vignettes/datatable-sd-usage.html

.SD is only available in the second argument (the 'j' arg, 
considering DT[i, j, ...]

==

Output of  ?.SD 
---------------

.SD, .BY, .N, .I, .GRP, and .NGRP are read-only symbols for use in j. .N can be used in i as well. See the vignettes and examples here and in data.table. .EACHI is a symbol passed to by; i.e. by=.EACHI.

These symbols used in j are defined as follows.

.SD is a data.table containing the Subset of x's Data for each group, excluding any columns used in by (or keyby).

.BY is a list containing a length 1 vector for each item in by. This can be useful when by is not known in advance. The by variables are also available to j directly by name; useful for example for titles of graphs if j is a plot command, or to branch with if() depending on the value of a group variable.
(girish: if by=.(foo, bar), then .BY$foo will have value of foo, .BY$bar will have bar. Since these are grouped, columns foo and bar here will have a single value only.)

.N is an integer, length 1, containing the number of rows in the group. This may be useful when the column names are not known in advance and for convenience generally. When grouping by i, .N is the number of rows in x matched to, for each row of i, regardless of whether nomatch is NA or NULL. It is renamed to N (no dot) in the result (otherwise a column called ".N" could conflict with the .N variable, see FAQ 4.6 for more details and example), unless it is explicitly named; e.g., DT[,list(total=.N),by=a].

.I is an integer vector equal to seq_len(nrow(x)). While grouping, it holds for each item in the group, its row location in x. This is useful to subset in j; e.g. DT[, .I[which.max(somecol)], by=grp].

.GRP is an integer, length 1, containing a simple group counter. 1 for the 1st group, 2 for the 2nd, etc.

.NGRP is an integer, length 1, containing the number of groups.

.EACHI is defined as NULL but its value is not used. Its usage is by=.EACHI (or keyby=.EACHI) which invokes grouping-by-each-row-of-i; see data.table's by argument for more details.

See Also
data.table, :=, set, datatable-optimize

Examples
DT = data.table(x=rep(c("b","a","c"),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1)
DT
X = data.table(x=c("c","b"), v=8:7, foo=c(4,2))
X

DT[.N]                                 # last row, only special symbol allowed in 'i'
DT[, .N]                               # total number of rows in DT
DT[, .N, by=x]                         # number of rows in each group
DT[, .SD, .SDcols=x:y]                 # select columns 'x' and 'y'
DT[, .SD[1]]                           # first row of all columns
DT[, .SD[1], by=x]                     # first row of 'y' and 'v' for each group in 'x'
DT[, c(.N, lapply(.SD, sum)), by=x]    # get rows *and* sum columns 'v' and 'y' by group
DT[, .I[1], by=x]                      # row number in DT corresponding to each group
DT[, .N, by=rleid(v)]                  # get count of consecutive runs of 'v'
DT[, c(.(y=max(y)), lapply(.SD, min)),
        by=rleid(v), .SDcols=v:b]      # compute 'j' for each consecutive runs of 'v'
DT[, grp := .GRP, by=x]                # add a group counter
DT[, grp_pct := .GRP/.NGRP, by=x]      # add a group "progress" counter
X[, DT[.BY, y, on="x"], by=x]          # join/merge within each group
[Package data.table version 1.13.2 Index]

==

For piping with data.table, see https://eliocamp.github.io/codigo-r/en/2019/07/why-i-love-data-table/

==

to plot quickly:
plot(density(rlnorm(1000))) (geom_bar(aes()))
or
hist(df$column) (geom_histogram(aes(x =))

refer to https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf

use ..count..
ggplot(es[cntry == "PT"]) + geom_bar(aes(x = cgtsmke1, 
               y = ..count../sum(..count..) * 100)) + ylab("%")
==

 na.rm = T is your friend

(remove NA values)

==

passing column names inside a list .() when grouping:

av[, .(mean = mean(price), median = median(price)), by = c("room_type")]

This names the columns

==

Recording 3/10

List is like an array (with indexes 1..n) and all the way to dictionary. It can have 'names' that look like keys, and elements can be of different type, including vectors.

When you run tests, you get result as a list, which will have p-value, mean, median, etc.

listname$element_name 
listname[[x]] and listname[x] also works (when it looks like an array with numerical indexes

Vectors can only contain 1 type of values (cannot mix)
c(...) is a vector
a_vector[2] is how you refer 

rm(list = ls()) removes everything from the environment
  	
# example data
L = list(X = 1, Y = 2, Z = 3)

==

In data table, following is an idiom:
lapply(.SD, function(x) ..., by = , .SDcols = "x"

(it lacks default .x and .y function arguments of tidyverse

--

mapply can iterate through 2 or more lists, taking i-th
element of each list -- so these lists passed in arg have
to be same length. mapply is a version of lapply.

sapply - s stands for simple (outputs vector)

mapply vs sapply: https://www.rforexcelusers.com/lapply-sapply-mapply-apply-function/

---

lapply() results in a list. so you can use
this in 
dt[ , (cols) := lapply(.SD, "*", -1), .SDcols = cols]

(lapply takes only 2 args, this guy is applying 3, because -1 is an argument to
function "*")

(use := causes assigment to columns, if you leave out :=
columns remain unchanged)

There are a few tricks here:

Because there are parentheses in (cols) :=, the result is assigned to the columns specified in cols, instead of to some new variable named "cols".
.SDcols tells the call that we're only looking at those columns, and allows us to use .SD, the Subset of the Data associated with those columns.
lapply(.SD, ...) operates on .SD, which is a list of columns (like all data.frames and data.tables). lapply returns a list, so in the end j looks like cols := list(...).

or

carsDT[, lapply(.SD, mean), by=.(am, vs), .SDcols = c("hp", "wt", "disp")]

--

there is just lapply and sapply. sapply() results in a vector.
mapply() is generalized sapply(). Since it gives out a vector,
you can use it here:
us[, c16 := mapply(function(x) ifelse(x > 0, dt[ranking == (x - 1), city], NA), c15)]

you are assigning a vector to a specific column here.

all data frames are just lists (each element being a vector)

Function applied to each element of x (first arg of lapply or sapply)

--

ifelse(test, x, y) returns a list/vector if 'test' arg is a list/vector, even
though condition is applied to each element in a list.

So you can assign ifelse() to the name of a column:
dt1[, PythonUser := ifelse(LanguageWorkedWith %like% "Python", TRUE, FALSE)]

doc:
ifelse returns a value with the same shape as test which is filled with elements selected from either yes or no depending on whether the element of test is TRUE or FALSE.


--

https://www.guru99.com/r-apply-sapply-tapply.html
https://stackoverflow.com/questions/16846380/how-to-apply-same-function-to-every-specified-column-in-a-data-table

3.3.1 of https://franknarf1.github.io/r-tutorial/_book/tables.html#tables

====

To take difference of subsequent row values do:
dt[, shift(Colname) - Colname]
This will add NA to first row 

DT[ , D := C + shift(B, 1L, type="lag")]
# or equivalently, in this case,
DT[ , D := C + shift(B)]

====
lapply to all columns, and group by column c1, and omit NAs:

setDT(df1)[, lapply(.SD, na.omit) , by = c1]

or

setDT(df)[, lapply(.SD, function(x) x[!is.na(x)]) , by = c1]

==

To print every column use .SD
es[, .SD] is same as simply "es"

https://cran.r-project.org/web/packages/data.table/vignettes/datatable-sd-usage.html
https://rpubs.com/josemz/SDbf

==

append() will concatenate 2 lists, so

es[, append(list(gndr = as.factor(gndr)), .SD), .SDcols = !"gndr"]

will print all columns, change gndr to a factor

Caution: doing list(gndr = as.factor(gndr), .SD) will cause
column names to get .SD.colname. list(element, another_list) is
what you are doing (not concatenation)

==

.GRP will give you all rows in group when you use by=

==

To print:

print(paste(x,"raised to the power", y, "is", result))

==

Basic plotting (not ggplot2):

(see cheatsheet http://publish.illinois.edu/johnrgallagher/files/2015/10/BaseGraphicsCheatsheet.pdf)


# We'll draw every plot in two ways:
#   1. With the use of basic plotting functions: 
#           - best for ad-hoc plots for your own use
#   2. With the use of the ggplot2 package: more complex, but nicer plots:
#           - best for plots that you want to export and use later (in your reports, assignments, papers, etc.)

1) Scatterplot (points) and lineplot

x = c(7.5, 9, 7, 7, 10.5, 8.5, 10, 12.5, 9.5, 10.5)
y = c(65, 70, 66, 68, 66, 64, 71, 67, 72, 75)
data <- data.frame(x, y)
rm(x, y)
plot(data) # scatterplot
plot(data$x, data$y, "l") #line plot
data <- data[order(data$x),]
plot(data$x, data$y, "l") # line plot of ordered x

Not needed:
plot(data$x,data$y, "b") # lines and points
plot(data$x,data$y, "c") # line parts without points
plot(data$x,data$y, "o") # lines and points (line overplotted over points)

Prettifying:
plot(data$x,data$y, "b", xlab = "vector X", ylab = "vector y", main = "EXAMPLE 1a")

plot(data$x,data$y, "b", xlab = "vector X", ylab = "vector y", main = "EXAMPLE 1a",
     col = "blue", font = 1, lty = 2, lwd = 2)

# main - main title of the plot
# xlab ? X axis label
# ylab ? Y axis label
# col - graph color (you can set many colors by setting col as a vector or a color palette)
# col.main - color of a main title
# col.lab - color of labels of both x and y axes
# font ? font type (1 - normal, 2 - bold, 3 - italic, 4 ? bold italic)
# lty ? line type (1 - line, 2 - dashed, 3 - dotted, 4 ? dash-dot, 5 ? long dash, 6 ? double dash)
# lwd - line thickness (by default 1).

2) barplot: when you have bins. Your y variable are values in these
bins and you name these bars.

data <- data.frame(
  name = c("Adam", "Beatrice", "Charles", "Dorothy"),
  age = c(65, 66, 54, 52)
)

barplot(data$age)

barplot(data$age,
        main = "Example 2a",
        xlab = "age",
        ylab = "name",
        names.arg = data$name,
        col = "darkred",
        horiz = TRUE)

# notice main and names.arg variables above. Rest is not needed.

3) piechart:

data <- data.frame(
  name = letters,
  group = sample(c(0,1), length(letters), replace = T)
)

pie(data$group)
pie(table(data$group))

Note: ggplot can do piechart:
ggplot(data = p, aes(x = "", y = frequency, fill = label))+
  geom_bar(stat = "identity")+coord_polar("y", start = 0)

4a) histogram: (plots frequency on y-axis)

sample <- data.frame(x = rnorm(200))
hist(sample$x)
hist(sample$x, probability = T)
hist(sample$x, probability = T, border = "black", col = "green", 
density = 50)

aside: The difference between the histogram and the bar chart is that the number of the bins of a histogram is not determined a priori and the bins are set to represent the continous scale of the data (i.e. we need to create „categories” for the continous scale)

4b) density plot or kernel density plot: same as histogram except instead
of bars you get a smoothed line
plot(density(x))

==

data.table is also a data.frame.

Advantage of data.table is that it provides grouping. data frame
does not have grouping.
The 3rd arg inside [] is the grouping variable for data.table
we use SQL syntax. 1st arg is row, second is column (same as data frame)

in data table you can do dt[month == 1], when instead you need
in data frame df[df$month == 1,] 
meaning, you can leave out , and df$ 
for data table.
He says, use data frame syntax always (even in tidyverse) because
you can read it easily.

# subseting columns
fl1 <- fl[,month]
in data frame, use f1[,"month"] // month is name of column
fl1 <- fl[,c(year, month)]
fl1 <- fl[,c("year", "month")] # the data.frame syntax
fl1 <- fl[,list(year, month)] # this will work for both dataframe
  and data table. in fact, you cannot use quotation mark inside list()
fl1 <- fl[,.(year, month)] # here ".()" is a synonym for list()

In data table you can use expressions in the column argument.
In data frame you can use expression only in row argument (where
row element is an element of a vector)

you are creating new columns, one row each containing 
number of rows where month is 1-6, etc.
fl1 <- fl[,.(first_half = sum(month <= 6), second_half = sum(month > 6), av_delay = mean(dep_delay, na.rm = T))]
fl1

same as above:
fl2 <- fl[month %in% c(1:6), length(month)]

grouping is where data table shines. last arg is grouping
by month. also we remove NA values.
fl1 <- fl[,.(mean_delay = mean(dep_delay, na.rm = T)),.(month)]

 fl[,.(mean_delay = mean(dep_delay, na.rm = T), departures = .N, departures = length(dep_delay)),.(month)]
.N means number of rows. It is the same as doing length(dep_delay)
you should avoid 2 columns with same name (which he did not do above)

fl[,.(mean_delay = mean(dep_delay, na.rm = T), departures = .N),.(month, origin)]
group by month and airport from where flight originates.

Merging: He uses data frame for illustrating merging, and he 
says this is sufficient. 

See when merging is not 1-1. Rows will missing column data
in one or the other df will be dropped, unless you include
all.x = T or all.y = T. Here you will have NA for missing values.
value for all.x is taken for name of column in final result.

n-to-1 match: for repeating values in column which is used
for merging, then repeated values will repeat n times
every possibility is repeated.

==

covariance, correlation:
https://www.simplilearn.com/covariance-vs-correlation-article

chisq test vs fisher's exact test
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5426219/#:~:text=Fisher's%20exact%20test%20is%20practically,is%20one%20of%20exact%20tests.

The chi-squared test is used to compare the distribution of a categorical variable in a sample or a group with the distribution in another one. If the distribution of the categorical variable is not much different over different groups, we can conclude the distribution of the categorical variable is not related to the variable of groups. Or we can say the categorical variable and groups are independent.

==

in data.table, you can use variables as column names by using
either ..varname or get(varname)

A modern approach is to use ..:

raw[ , ..col1]
.. "looks up a level" to find col1.

https://stackoverflow.com/questions/9864055/get-columns-by-string-from-data-table

--

you don't need to use anonymous function :
Here min and max are args to runif:

lapply(1:4, runif, min = 0, max = 10) 

you can also use do.call() - see below.

--

unlist(a_list) will give a vector.

--

to return multiple values from function, return a list.

=======================================================

lecture notes - advanced R

=======================================================

is.data.frame()
is.nan()
is.na()
is.vector()
is.list()
there is almost always a is...() function for every class or type

we us | for vectors (vectorized operators, return vector), but || for scalars
use any() and all()


## 1.2. ifelse function - vectorised equivalent
# Result is a vector with the same dimensions as the one in the condition.

if(c(1:5) %% 2 == 1) { print('odd')} else {print('even')}
# above will give warning because c(1:5) is a vector, and it will
print first item only (odd). Use ifelse()
ifelse(c(1:5) %% 2 == 1, "odd", "even")

--
About apply family:

# 5. Family of apply functions  ------------------------------------------------
# 
# In statistical programming, loops are usually over elements of certain objects: 
# matrixes or data.frames. To iterate over rows, columns or elements of object we 
# can use apply function. They are faster and offer shorter syntax (albeit less 
# intuitive).

# Apply functions forms family of functions, starting from basic apply to more
# specialised. The most prevalent functions are:

# 1. apply
# 2. lapply
# 3. sapply
# 4. vapply
# 5. tapply
# 6. mapply


# 5.1. apply -------------------------------------------------------------------
# Loop which applies a function to rows or columns of a table.

# Usage:
# apply(X, MARGIN, FUN, ...)

# X - object with margins - rows and columns
# margin - types of margin - rows (1) or columns (2)
# FUN - function to be performed on each element of given dimention (margin)
# ... - aditional arguments of function

# Example:
table <- cbind(c(1:8),c(10:17),c(15:8))
table

apply(table, 1, mean) # mean of each row
apply(table, 1, mean, na.rm = T) # mean of each row
apply(table, 1, function(x) mean(x, na.rm = T)) # mean of each row
apply(table, 2, max)  # max of each column

# Very often in apply is impelemented anonymous function - written 'on the run'.
table2 <- apply(table, 1:2, function(x) x^2-x/exp(x)) 

# Print results
table2

# Of course we could use vectorised operations:
table3 <- table^2-table/exp(table)

# Let's examine a function which returns a vector:
apply(table, 1, range)


# 5.2. lapply function ---------------------------------------------------------
# lapply() function works with lists, applying to each element a uer-defined or
# built-in function. The return object is a list

# Usage:
# lapply(list, FUN,...)

# Arguments:
# list - an object which is list (so data.frame can be used!!)
#  ... additional parameters of a function

# First let's understand what is a list:

# List creation:
list1 <- list()

# Adding fields (od different types)
list1[[1]] <- 1:100
list1[['iris']] <- iris
list1[['letter']] <- 'P'

# indexing:
list1[['iris']]
list1[[2]]
list1[2]
list1$iris

# List are a quite common objects in R enviroment:
model <- lm(Sepal.Length ~ Sepal.Width, data = iris)
class(model)
is.list(model)
names(model)

# Indexing list of class lm
model[['coefficients']]
model[['residuals']]

model$fitted.values

# Data.frame is also a list...
is.data.frame(iris)
is.list(iris)

# Now let's go back to lapply.

# Let's define a list:
L <- list(a = c(1, 2), 
          b = c(3, 5, 7)
)
# Apply sinus function to list elements:
L2 <- lapply(L, sin)

# Investigating result
L2

# Another example with anonymuos function:
L3 <- lapply(L, function(x) {x^2}) 
L3

# And even with function return one value... 
L4 <- lapply(L, mean)
#... result is still a list 
L4 

# Here a magical function:
unlist(L4)

# In the end let's look at the function with additional arguments:
lapply(1:4, runif, min = 0, max = 10) 


# 5.3. sapply ------------------------------------------------------------------

# Sapply is simplified lapply function. Function returns:
# 1. Vector, if all elements of the result are single values
# 2. Matrix if all elements of the result look like matrix 
# 3. List otherwise.

# Objects for examples:
L0 <- list(a = 1, b = 3)
L1 <- list(a = c(1, 2), b = c(5, 6))
L2 <- list(a = c(1, 2, 3), b = c(5, 6))

# Examples
W0 <- sapply(L0, function(x) { x^3 })
W1 <- sapply(L1, function(x) { x^3 })
W2 <- sapply(L2, function(x) { x^3 })

# Let's analize results:
is.vector(W0);W0
is.matrix(W1);W1
is.list(W2);W2

# If we want ordinary lapply() we can set simplify = F 
W <- sapply(L, function(x){x^3}, simplify = F); W # list
W1 <- sapply(L1, function(x){x^3}, simplify = F); W1 # list
W2 <- sapply(L2, function(x){x^3}, simplify = F); W2 # list

# 5.4 mapply -------------------------------------------------------------------

# Vectorised lapply.
# mapply(FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE)
rep(1, 4)
rep(4, 1)

# Examples:
mapply(rep, 1:4, 4:1)
mapply(rep, times = 1:4, x = 4:1)
mapply(rep, times = 1:4, MoreArgs = list(x = 42))
mapply(function(x, y) seq_len(x) + y,
       c(a =  1, b = 2, c = 3),
       c(A = 10, B = 0, C = -10))

# 6. Other loops ---------------------------------------------------------------

# 6.1 do.call() - it constructs a function call from string 
(without qutoes) or function name

see https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/do.call
Usage
do.call(what, args, quote = FALSE, envir = parent.frame())
Arguments
what
either a function or a non-empty character string naming the function to be called.

args
a list of arguments to the function call. The names attribute of args gives the argument names.

quote
a logical value indicating whether to quote the arguments.

envir
an environment within which to evaluate the call. This will be most useful if what is a character string and the arguments are symbols or quoted expressions.

----------------------------------------------------------------

ex <- mapply(rep, 1:4, 4:1)
ex

# Examples

# 1.
do.call(c, ex) 
unlist(ex)

# c(ex[[1]], ex[[2]], ex[[3]], ex[[4]])
# 
# res <- numeric()
# for(i in 1:length(przyklad)){
#   wyniki <- c(res, przyklad[[i]])
# }
# res

# 2.
do.call(sum, ex)
sum(unlist(ex))

# 3.
library(ggplot2)
subsets <- split(diamonds, diamonds$cut)

res <- lapply(podzbiory, head)
res <- do.call(rbind, res)
res <- as.data.frame(res)
res

# 6.2. replicate() -------------------------------------------------------------

# Replicates the procedure certain amounts of time.

# Population vector
pop <- rnorm(10000, 10, 1)

# Sampling (25000 repeats):
est1 <- replicate(expr = mean(sample(x = pop, size = 5)), n = 25000)

# 6.3 sweep() - used for matrixes , similar to apply

------------------------------------------------------------------

see https://stackoverflow.com/questions/3444889/how-to-use-the-sweep-function

# apply for operators:
data(iris)
iris2 <- iris[, -5]

iris_avgs <- apply(iris2, 2, mean)
iris_sd <- apply(iris2, 2, sd)

iris_stand <-  sweep(iris2, 2, iris_avgs, "-") 
iris_stand <- sweep(iris_stand, 2, iris_sd, "/")

summary(iris_stand)
-----------------------


Functions
=====================================================

# But what happen if arguments are not numbers? Let's try it:
my.function(1, 2, '3')

# Obviously we need defense programming here. We will go back to this later on,
# now below we present some very basic example:
my.function2 <- function(a, b, c) {
  if(class(a) == "numeric" & class(b) == "numeric" & class(c) == "numeric") {
    a * b + c
  }
  else {
    print("arguments of the function aren't all numeric")
  }
}

# Functions are automatically vectorized

my.function <- function(a, b, c) {
  a + b + c
}

# Let's notice, that our functions is vectorized
vector1 <- 1:5
vector2 <- 1:5
vector3 <- 1:5

# And test:
my.function(vector1, vector2, vector3)

# We can also declare some argument optional:
f.example <- function(a1, a2, a3 = NULL){
...
}

# however...
f.example <- function(a1, a2, a3){
  a1 + a2
}
f.example(1, 2)

# This is called lazy evaluation.

# You can check arguments of the function with args():
args(lm)
args(f.example)


# Generic functions, use of ellipsis ... :

# We want line type to be default:
myplot <- function(x, y, type = "l", ...) {
  plot(x, y, type = type, ...) # pass "..." to "plot" function
}

# Let's call the function
myplot(x, y)

# however, new function has a lot of limitation...
myplot(x, y, lwd = 4)

# Another application of '...'
sum1 <- function(...) {
  s <- 0
  arguments <- list(...) # arguments for the list
  for (i in 1:length(arguments)) {
    s = s + arguments[[i]]
  }
  return(s)
}

sum1(1, 2)

# function can be argument of other function:
fun1 <- function(x, FUN, ...){
  FUN(x, ...)
}

==========================================

Lecture on operator defining and defensive programming

# binary operators (eg. +, -, %%, %in%, %>%) are in fact functions, which have two 
# arguments, one the LHS (left hand side) one on the RHS. User defined operators
# should start and end with percent symbols. Let's learn how to right them on our 
# own.

# first example - sum operator:
`%+%` <- function(x, y) sum(x, y)

5 %+% 6
5 + 6

# Watch out - it is easy to substitute original operator!
`+` <- function(x, y) sum(x, -y)
5 + 6

# let's delete it at never repeat it ever again.
rm(`+`)

# another example - imitation of head() function:
head(1:10, 4)
head(iris, 4)

`%h%` <- function(x, y) head(x, y)

iris %h% 4
library(ggplot2)
diamonds %h% 15

# Exercise 1.
# Define operator %sample%, which will return random sample of size n from given 
# vector. Exemplary call:

1:100 %sample% 10

# Exercise 2.
# Row sums can be tricky. Ordinary `+`` operator is dangerous, 
# when NA's occurs in dataset. On the other hand, rowSums and apply functions are
# relatively incovenient. Define new binary operator %+na% which ignores missings 
# when add values to each others, e.g.:

2 + NA 
# [1] NA

2 %+na% NA
# [1] 0

# Exercise 3. 
# Create operator which works like LIKE operator in SQL.

cities <- c('Barcelona', 'Rome', 'Warsaw')

cities %LIKE% 'War'
# [1] c(F, F, T)



### 2. Defensive programming ---------------------------------------------------

# According to wikipedia:
# 
# Defensive programming is a form of defensive design intended to ensure the continuing 
# function of a piece of software under unforeseen circumstances. Defensive programming 
# practices are often used where high availability, safety, or security is needed.
  


# 2.1. Error handling ----------------------------------------------------------

Sys.setenv(LANG = 'en')

f1 <- function(x){
  sqrt(x)
  print(x)
}

# Error:
f1('Ala')

stops program with error

# Let's run again with try() function: 
f1 <- function(x){
  try(sqrt(x))
  print(x)
}
# Run:
f1('Ala')

prints error but proceeds as though nothing happened
prints 'Ala' from print(x)

# So, try() function:
# 1) printed error message,
# 2) allowed function to work further. 

# But only errors are taking care of:
f1(-10)

prints warning that NaN was produced, not error

# by the way, we can change importance of this error:
options(warn = 2)
f1(-10)

# by default:
options(warn = 1)
f1(-10)

# The result of try function can be store in variable"
good = try(2 + log(2))
good

bad = try(2 + log('2'))
bad

# It can be executed silently:
bad = try(2 + log('2'), silent = T)

# Let's investigate object returned after error:
bad

# Attributes (class and condition):
attributes(bad)

# We can use it to modify message for user:
if(class(bad) == "try-error") print("Erro no 1234: check company policy handbook p. 567")

# In the code below try() function is used to check where error occurs in
# apply function:
elements <- list(1:10, c(-1, 10), c(TRUE, FALSE), letters)
results <- lapply(elements, function(x) sqrt(x))

results will be undefined 

# We can include the try() error handler:
results <- sapply(elements, function(x) try(sqrt(x), silent = TRUE))

# Now we are able to detect fields which result in critical error:
is.error <- function(x) inherits(x, 'try-error')
lapply(results, is.error)

inherit checks whether attribute class is 'try-error'
same as class(x) == try-error

# A bit more universal function is tryCatch(), which handles: errors, warnings, 
# messages. User can choose what kind of behavior will occur if any of the above
# happen.
example <- function(code) {
  tryCatch(code,
           error = function(c) "error",
           warning = function(c) "warning",
           message = function(c) "message"
  )
}
example(log(-2))
example(log('-2'))
example(library(dplyr))

# 2.2. Assertions --------------------------------------------------------------

# While creating functions, it is recommended to put at the beginning of the code
# conditions which check whether arguments of the function have correct type, class
# and format. This conditions are called assetions.
# 
# They are useful because:
# - prevent from making unnecesary computations (if arguments have wrong form,
#   estimations, even if are partially correct, will be useless)
# - allows to correct mistakes quickly,
# - allows to design messages for users more intuitive than standard R errors and 
#   warnings.


# For examples, we will use following procedures which imitates errors, warnings
# and messages:
stop("!")
warning("!")
message("!")

# Generally, we should use errors if exception is critical, and warning if there
# is a potential problem, event though arguments and data fulfilled every necessary
# requirement.

# For example:

log_user <- function(x){
  if(!is.numeric(x)){
    stop('Argument is not a number')
  }
  if(x < 0){
    warning('Argument is negative')
  } else{
    message('Everything is just fine. Keep calm and compute.')
  }
  log(x)
}

log_user(10)
log_user('10')
log_user(-10)

# Because if and stop() are used frequently together, there is stopifnot() function
# available:
f1 <- function(x){
  stopifnot(is.numeric(x))
  sqrt(x)
}
f1('Ala')
f1(10)


# With all():
f1 <- function(x, y, z){
  stopifnot(all(is.numeric(x), is.numeric(y), is.numeric(z)))
  sqrt(c(x, y, z))
  
}
f1('Ala', 2, 3)

# with all.equal()
f1 <- function(x, y){
  stopifnot(all.equal(x,y))
  sqrt(c(x, y))
}
f1(1, 2)

# Another assertions can be found in package asserthat or testit:

install.packages('assertthat')
library(assertthat)


assert_that() # stopifnot(), but allows for user defined messages
see_if() # returns logical value, message is only an attribute
validate_that() # returns true if condition is fulfilled and error message in opposite case.

f1 <- function(x){
  assert_that(is.numeric(x), msg = 'Rookie mistake!')
  sqrt(x)
}
f1('Ala')

f1 <- function(x){
  see_if(is.numeric(x))
  print(see_if(is.numeric(x)))
  sqrt(x)
}
f1('Ala')

f1 <- function(x){
  validate_that(is.numeric(x))
  print(validate_that(is.numeric(x)))
  sqrt(x)
}
f1('Ala')


# Other assertions:
# is.flag(x): is x TRUE or FALSE? (a boolean flag)
# is.string(x): is x a length 1 character vector?
# has_name(x, nm), x %has_name% nm: does x have component nm?
# has_attr(x, attr), x %has_attr% attr: does x have attribute attr?
# is.count(x): is x a single positive integer?
# are_equal(x, y): are x and y equal?
# not_empty(x): are all dimensions of x greater than 0?
# noNA(x): is x free from missing values?
# is.dir(path): is path a directory?
# is.writeable(path)/is.readable(path): is path writeable/readable?
# has_extension(path, extension): does file have given extension?

install.packages('testit')
library(testit)

# testit package also includes functions to detect,
# whether there was an error or warning was generated

has_error(10 + 10)

has_error(10 + "10")

has_warning(10 + 10)

has_warning(mean(NULL))


# Sometimes, if we want to be sure that some code will be executed, before function
# will ends (even when an error occured) we can use expression on.exit():

plot_with_big_margins <- function(...)
{
  old_pars <- par(mar = c(10, 9, 9, 7))  
  on.exit(par(old_pars))
  plot(...)
}

# Now originally margins are restored after the function call: 
plot_with_big_margins(with(cars, speed, dist))
plot(with(cars, speed, dist))


# More examples can be found here:
# https://stackoverflow.com/questions/28300713/how-and-when-should-i-use-on-exit

### 3. invisible() -------------------------------------------------------------

# Sometimes it is convenient to return as a function result the object that which 
# is invisible. This is especially useful for functions that return result, which 
# can be assigned to some object, but if it is not assigned, will not be displayed 
# in the console.


reg_plot <- function(formula, data) {
  # estimate regression model
  fit = lm(formula, data)
  # plot diagnostic plots residuals
  par(mfrow=c(2,2)) # Change the panel layout to 2 x 2
  plot(fit)
  par(mfrow=c(1,1)) # Change back to 1 x 1
  # generate summary
  print(summary(fit))
  # return the model as "invisible" object
  invisible(fit)
}

# Example:
reg_plot(Sepal.Length ~ ., iris)

# but...
model <- reg_plot(Sepal.Length ~ ., iris)

# here more about diagnostics plots:
# https://data.library.virginia.edu/diagnostic-plots/

# Real case example of invisible() function is here:
hist(iris$Sepal.Length)

# however we can assign result to a plot...
histogram <- hist(iris$Sepal.Length)

# ... which is a list containing information bins:
str(histogram)

====================================================================== 

attributes() is the most important:

mode() vs typeof() vs class()
https://stackoverflow.com/questions/35445112/what-is-the-difference-between-mode-and-class-in-r

also:
attributes() vs attr() vs structure()
https://statisticsglobe.com/attr-attributes-structure

(x = system.time(.....))

r$> attributes(x)
$class
[1] "proc_time"

$names
[1] "user.self"  "sys.self"   "elapsed"    "user.child" "sys.child"

Find what methods/functions are availabel for class:
r$> methods(class="proc_time")
[1] print   summary
see '?methods' for accessing help and source code

r$> summary(x)
   user  system elapsed
      0       0       0

To access ( use [""] syntax ):
r$> x["user.self"]  # why "user.self", not "user"? See attributes(x)
user.self
        0

==

> sessionInfo()
R version 2.13.1 Patched (2011-07-08 r56332)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
 [5] LC_MONETARY=C              LC_MESSAGES=en_GB.UTF-8   
 [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods  
[8] base
==

How to access the last value in a vector?

I use the tail function:

tail(vector, n=1)
==

for package tests:
What you are doing is how I have always checked my packages:

1. Run R CMD check pkg_tarball.tar.gz
2. mv pkg.Rcheck/pkg-Ex.Rout pkg_sources/tests/Examples/pkg-Ex.Rout.save
3. Next R CMD check pkg_tarball.tar.gz checks against the new Example output

Are you sure you are getting the newly created pkg-Ex.Rout file and placing
it in the correct part of the package and adjusting the name
to pkg-Ex.Rout.save?

The only time I ever had a problem with this was when I inadvertently used
a .Rout file from a check with --as-cran.

==	

How do I pass column name as variable to data.table in R? [duplicate]

use ..var

From v1.10.2 onwards, you can also do:
dt[, ..cols]

or:
dt1=df[,c(var1,var2), with=F]
Think of "with=F" as making "j" part data.table behave like that of data.frame

==

